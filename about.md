---
layout: post
title: About me
date: 2024-06-01
permalink: /about
---

Hello! I am Romit. I love building data-driven tools and products. I have `(Current year - 2018)` years of work experience in arranging matrices.

## A bit about my experience

- Sarvam.ai, [February 2025-Present]
    - I worked on the post-training quantization and inference optimization of [Sarvam-M, a 24B LLM](https://www.sarvam.ai/blogs/sarvam-m).
    - I built a central store for storing pre-training datasets based on WebDatasets that was highly fault-tolerant and scalable.
    - I worked with TensorRT LLM, vLLM, WebDatasets, and K8s.

- Meraki Labs, [December 2023-January 2025]
    - I worked on pre-training [small audio language models](https://huggingface.co/11mlabs/indri-0.1-124m-tts). I spent time understanding the [audio domain](https://pypi.org/project/audiotoken/) and [how its modeling works](https://www.indrivoice.ai/blog/2024-11-19-audio-modelling).
    - I also worked on solving the [gaps in the inferencing of small multimodal models](https://github.com/romitjain/gpt-benchmark) and wrote a [few GPU kernels](https://github.com/indri-voice/vit.triton) to accelerate inferencing.
    - I primarily worked with Triton, CUDA C, and PyTorch.

- epifi, [November 2020-October 2023]
    - I worked as a Senior data scientist where I primarily trained and deployed real-time computer vision and machine learning models.
    - This involved building infrastructure for real-time and batch models, like a ton of real-time feature engineering, optimizations for deploying deep learning and ML models with lower latency (TF lite, quantization, in memory DBs), and building observable services serving ML models.
    - I worked extensively with Tensorflow, Docker, PySpark, Airflow, EFK stack, and the usual AWS stack.

- Postman, [January 2018-November 2020]
    - I worked as a Technical lead in the data science team and was the founding member of the data team.
    - I built and designed several internal tools including.
        - [Data APIs](https://medium.com/better-practices/api-driven-analytics-d980b28cb15e): This was my major work at Postman that helped Postman to be data-aware and data-driven.
        - Data testing framework (Based on Looker and DBT) which checked the integration and correctness of data.
    - [Knowledge Repository](https://blog.postman.com/how-postman-built-a-knowledge-repository/).
    - I worked with SQL, Redshift, Looker, DBT, and PowerBI.

- I was on the team that built the project [Panoptic](https://panoptic.in).

## A bit about what I love doing

- Tech I love working with - Python, Triton, PyTorch, SQL, Docker, FastAPI.
- Areas I am interested in:
    - Systems around LLMs
    - Applied deep learning, especially computer vision
    - Human in-loop decisions
- Reading [books](https://www.goodreads.com/user/show/100308617-romit), playing cricket, and petting cats.
- Obsessed with calendars, to-dos, tracking every little thing, and shiny productivity apps.
