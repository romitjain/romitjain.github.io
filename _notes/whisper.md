---
title: Whisper
tags: research-papers deep-learning
date: 2023-12-15
---

1. TOC
{:toc}

## Contributions

There are two major contributions of the paper

1. Train on weakly supervised dataset
2. Training a multi task model

### Weak supervised

- This just means that the data is not perfect, it has noise and can have mistakes
- Data is not gold standard, not labelled by humans but by other pretrained ASR models
- "Transcript-ese": Data generated by other ASR models
    - They used heuristics to remove sub par quality data or data generated by ASR models

### Multi task

- Model is trained on multiple tasks
- Transcribing English to English
- Transcribing X language to X language
- Transcribing X language to English

## New concepts to me

### Log mel spectrogram

- A colour photo of a speech
- X axis is time and y axis is in mels
- Mels is just a unit conversion from hertz (frequency) which represents how humans perceive sounds
- Colour of the photo depicts amplitude

### Tokenization?

- Why separate tokenization methods?
- Tokenization is just breaking the sentence into words and words into sub words, creating index for each sub word and converting that index into an embedding during the forward pass
- The naive way of doing tokenization involves a lot of rules and ends up creating a huge vocabulary. It is also tough to keep it updated since each new word will require a new token
- Specialized tokenization method helps tokenize any word across different languages since they are a mix of tokenizing characters and words
- How is tokenization and embedding related? Some answer [here](https://stackoverflow.com/questions/50184280/how-to-conceptually-think-about-relationship-between-tokenized-words-and-word-em?rq=3)
- Whisper uses: Byte level BTE tokenizer (not the contribution of this research paper)
- Reference of popular [tokenization](https://huggingface.co/docs/transformers/main/tokenizer_summary) methods

### Other ideas

- How to measure robustness?
    - Train on data D
    - Evaluate on the similar distribution `dev` dataset from D -> X
    - Evaluate on completely out of distribution dataset Y
    - If the model is completely robust, the error rate on X and Y should be same
- Models to try
    - CLD2 model for language detection
    - Maestro for x -> en translation
    - mSLAM-CTC for language identification
- Text normalizer
    - Rules/methods to convert text into a standard format. For example, `you're` and `you are` are converted to same token
    - This also helps in calculating WER
    - This is done manually and a fixed vocabulary is stored
- Greedy search vs Beam search
    - Instead of single token probabilities being selected at each timestamp, beam search enables to select the best sequence of tokens
    - In beam search if *width* is 2, then at each timestamp, the algorithm will select 2 best tokens while conditioning on 2 previous best tokens. This eventually results in search for best overall sequence
- CTC loss
    - In our case, input is an audio signal and output are words at discrete timestamps. To use a loss function for such scenarios, CTC is used
    - CTC is used to align the input and output sequences when the input is continuous and the output is discrete, and there are no clear element boundaries that can be used to map the input to the elements of the output sequence
    - Slightly complex, need to understand fully

### References

1. [YouTube video](https://www.youtube.com/watch?v=AwJf8aQfChE)
2. [Visual explanation of beam search](https://towardsdatascience.com/foundations-of-nlp-explained-visually-beam-search-how-it-works-1586b9849a24)
