---
title: Quickstart on LLMs
tags: deep-learning llms
date: 2023-12-01
---

1. TOC
{:toc}

## Quickstart on LLMs

### Begineer

1. If new to LLMs, start with this video to get an overview: [State of GTP by Andrej Karpathy](https://www.youtube.com/watch?v=bZQun8Y4L2A)
2. [Building LLM applications for production by Chip Huyen](https://huyenchip.com/2023/04/11/llm-engineering.html)
3. (Optional) [A Metrics-First Approach to LLM Evaluation - Galileo by Pratik Bhavsar](https://www.rungalileo.io/blog/metrics-first-approach-to-llm-evaluation)

### Intermediate

1. [A Hackers' Guide to Language Models by Jeremy Howard](https://www.youtube.com/watch?v=jkrNMKz9pWU)
   1. "The best way to learn about language models is to use them" from the video. And this video will teach to exactly do that
2. Master blog of how to serve LLMs in production: [Optimizing your LLM in production](https://huggingface.co/blog/optimize-llm)
3. How LLMs are trained?
   1. [RLHF: Reinforcement Learning from Human Feedback  by Chip Huyen](https://huyenchip.com/2023/05/02/rlhf.html)
4. How to server LLMs in memory-constrained environments?
   1. [KV Cache brief explainer](https://www.youtube.com/watch?v=80bIUggRJf4)
   2. [Understanding Llama2: KV Cache, Grouped Query Attention, Rotary Embedding and More](https://ai.plainenglish.io/understanding-llama2-kv-cache-grouped-query-attention-rotary-embedding-and-more-c17e5f49a6d7)
   3. Understanding basics of LoRa: [LoRA explained (and a bit about precision and quantization)](https://www.youtube.com/watch?v=t509sv5MT0w)
5. Also learn about quantization, flash attention

### Advanced

1. [vLLMs](https://blog.vllm.ai/2023/06/20/vllm.html): Serving LLMs faster
